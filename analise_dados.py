"""
AN√ÅLISE EXPLORAT√ìRIA DOS DADOS - TCC
====================================

Script para gerar an√°lise detalhada dos dados iniciais para o artigo.
"""

import pandas as pd
import numpy as np
from scipy.stats import ttest_ind
import warnings
warnings.filterwarnings('ignore')

def analyze_dataset():
    """An√°lise explorat√≥ria completa dos dados para o artigo"""
    print("üéì AN√ÅLISE EXPLORAT√ìRIA DOS DADOS - TCC")
    print("=" * 60)
    print("Autora: Vit√≥ria de Lourdes Carvalho Santos")
    print("PUC Minas - 2025")
    print("=" * 60)
    
    # Carregar dados
    print("\nüìä Carregando dados...")
    try:
        df = pd.read_csv('enrollments.csv', nrows=10000)  # Amostra maior para an√°lise
        print(f"‚úÖ Dados carregados: {df.shape[0]:,} registros e {df.shape[1]} colunas")
    except Exception as e:
        print(f"‚ùå Erro ao carregar dados: {e}")
        return None
    
    # 1. CARACTER√çSTICAS GERAIS DO DATASET
    print(f"\nüîç 1. CARACTER√çSTICAS GERAIS DO DATASET")
    print("-" * 50)
    print(f"‚Ä¢ Total de registros: {len(df):,}")
    print(f"‚Ä¢ Colunas dispon√≠veis: {len(df.columns)}")
    print(f"‚Ä¢ Per√≠odo dos dados: de {df['created_at'].min()} at√© {df['created_at'].max()}")
    
    # Missing values
    missing_pct = (df.isnull().sum() / len(df) * 100).round(1)
    cols_with_missing = missing_pct[missing_pct > 0].head(5)
    if len(cols_with_missing) > 0:
        print(f"‚Ä¢ Colunas com valores ausentes:")
        for col, pct in cols_with_missing.items():
            print(f"  - {col}: {pct}%")
    
    # 2. DISTRIBUI√á√ÉO POR STATUS DOS ESTUDANTES
    print(f"\nüìà 2. DISTRIBUI√á√ÉO POR STATUS DOS ESTUDANTES")
    print("-" * 50)
    status_counts = df['workflow_state'].value_counts()
    total = len(df)
    
    for status, count in status_counts.items():
        percentage = (count/total)*100
        print(f"‚Ä¢ {status.upper():<12}: {count:>6,} estudantes ({percentage:5.1f}%)")
    
    # Calcular taxa de evas√£o
    evaded_statuses = ['inactive', 'deleted', 'completed']  # Incluir completed como "sa√≠da"
    evaded = sum(status_counts.get(status, 0) for status in evaded_statuses if status in status_counts.index)
    evasion_rate = (evaded / total) * 100
    print(f"\nüö® TAXA DE EVAS√ÉO IDENTIFICADA: {evasion_rate:.1f}%")
    
    # 3. AN√ÅLISE TEMPORAL DAS MATR√çCULAS
    print(f"\nüìÖ 3. AN√ÅLISE TEMPORAL DAS MATR√çCULAS")
    print("-" * 50)
    df['created_at'] = pd.to_datetime(df['created_at'], errors='coerce')
    df['ano_matricula'] = df['created_at'].dt.year
    df['mes_matricula'] = df['created_at'].dt.month
    
    # Por ano
    matriculas_ano = df['ano_matricula'].value_counts().sort_index()
    print("Distribui√ß√£o por ano:")
    for ano, count in matriculas_ano.items():
        if pd.notna(ano) and ano >= 2020:  # Focar anos recentes
            percentage = (count/total)*100
            print(f"  {int(ano)}: {count:,} matr√≠culas ({percentage:.1f}%)")
    
    # Sazonalidade
    matriculas_mes = df['mes_matricula'].value_counts().sort_index()
    meses = ['Jan', 'Fev', 'Mar', 'Abr', 'Mai', 'Jun',
            'Jul', 'Ago', 'Set', 'Out', 'Nov', 'Dez']
    print("\nSazonalidade (top 6 meses):")
    for mes, count in matriculas_mes.head(6).items():
        if pd.notna(mes):
            percentage = (count/total)*100
            print(f"  {meses[int(mes)-1]}: {count:,} ({percentage:.1f}%)")
    
    # 4. AN√ÅLISE DE ATIVIDADE DOS ESTUDANTES
    print(f"\n‚è±Ô∏è  4. AN√ÅLISE DE ATIVIDADE DOS ESTUDANTES")
    print("-" * 50)
    df['total_activity_time'] = pd.to_numeric(df['total_activity_time'], errors='coerce')
    activity_data = df['total_activity_time'].dropna()
    
    if len(activity_data) > 0:
        activity_stats = activity_data.describe()
        print(f"‚Ä¢ Estat√≠sticas do tempo de atividade (horas):")
        print(f"  - M√©dia: {activity_stats['mean']:,.0f} horas")
        print(f"  - Mediana: {activity_stats['50%']:,.0f} horas")
        print(f"  - Desvio padr√£o: {activity_stats['std']:,.0f} horas")
        print(f"  - M√≠nimo: {activity_stats['min']:,.0f} horas")
        print(f"  - M√°ximo: {activity_stats['max']:,.0f} horas")
        
        # Categoriza√ß√£o por quartis
        q1 = activity_stats['25%']
        q3 = activity_stats['75%']
        
        df['categoria_atividade'] = 'Baixa'
        df.loc[df['total_activity_time'] >= q1, 'categoria_atividade'] = 'M√©dia'
        df.loc[df['total_activity_time'] >= q3, 'categoria_atividade'] = 'Alta'
        
        categoria_counts = df['categoria_atividade'].value_counts()
        print(f"\n‚Ä¢ Categoriza√ß√£o por n√≠vel de atividade:")
        for categoria, count in categoria_counts.items():
            percentage = (count/len(df))*100
            print(f"  - {categoria}: {count:,} estudantes ({percentage:.1f}%)")
    
    # 5. AN√ÅLISE POR TIPO DE ESTUDANTE
    print(f"\nüë• 5. AN√ÅLISE POR TIPO DE ESTUDANTE")
    print("-" * 50)
    if 'type' in df.columns:
        tipo_counts = df['type'].value_counts()
        for tipo, count in tipo_counts.items():
            percentage = (count/total)*100
            print(f"‚Ä¢ {tipo}: {count:,} estudantes ({percentage:.1f}%)")
    
    # 6. CORRELA√á√ÉO ENTRE ATIVIDADE E STATUS
    print(f"\nüîó 6. CORRELA√á√ÉO ENTRE ATIVIDADE E STATUS")
    print("-" * 50)
    
    if len(activity_data) > 0:
        # Atividade m√©dia por status
        activity_by_status = df.groupby('workflow_state')['total_activity_time'].agg(['mean', 'median', 'count'])
        print("Tempo de atividade por status:")
        for status, row in activity_by_status.iterrows():
            print(f"  ‚Ä¢ {status.upper():<12}: M√©dia {row['mean']:>8,.0f}h | Mediana {row['median']:>6,.0f}h | n={row['count']:,}")
        
        # Teste estat√≠stico
        active_activity = df[df['workflow_state'] == 'active']['total_activity_time'].dropna()
        other_activity = df[df['workflow_state'] != 'active']['total_activity_time'].dropna()
        
        if len(active_activity) > 30 and len(other_activity) > 30:
            try:
                t_stat, p_value = ttest_ind(active_activity, other_activity)
                print(f"\n‚Ä¢ Teste t-student (ativos vs outros):")
                print(f"  - Estat√≠stica t: {t_stat:.3f}")
                print(f"  - P-valor: {p_value:.6f}")
                significance = "SIGNIFICATIVA" if p_value < 0.05 else "n√£o significativa"
                print(f"  - Diferen√ßa estatisticamente {significance} (Œ± = 0.05)")
            except:
                print("‚Ä¢ N√£o foi poss√≠vel realizar teste estat√≠stico")
    
    # 7. AN√ÅLISE DE PERMAN√äNCIA
    print(f"\nüìä 7. AN√ÅLISE DE PERMAN√äNCIA DOS ESTUDANTES")
    print("-" * 50)
    df['dias_na_plataforma'] = (pd.Timestamp.now() - df['created_at']).dt.days
    permanencia_data = df['dias_na_plataforma'].dropna()
    
    if len(permanencia_data) > 0:
        perm_stats = permanencia_data.describe()
        print(f"‚Ä¢ Tempo de perman√™ncia na plataforma:")
        print(f"  - M√©dia: {perm_stats['mean']:,.0f} dias ({perm_stats['mean']/365:.1f} anos)")
        print(f"  - Mediana: {perm_stats['50%']:,.0f} dias ({perm_stats['50%']/365:.1f} anos)")
        
        # Por status
        permanencia_por_status = df.groupby('workflow_state')['dias_na_plataforma'].agg(['mean', 'median'])
        print(f"\nPerman√™ncia m√©dia por status:")
        for status, row in permanencia_por_status.iterrows():
            print(f"  ‚Ä¢ {status.upper():<12}: {row['mean']:>6.0f} dias (mediana: {row['median']:>6.0f})")
    
    # 8. INSIGHTS E CONCLUS√ïES
    print(f"\nüí° 8. PRINCIPAIS INSIGHTS PARA O ARTIGO")
    print("-" * 50)
    
    # Insight 1: Taxa de evas√£o
    if evasion_rate > 30:
        severity = "CR√çTICA"
    elif evasion_rate > 20:
        severity = "ALTA"
    elif evasion_rate > 10:
        severity = "MODERADA"
    else:
        severity = "BAIXA"
    
    print(f"‚Ä¢ TAXA DE EVAS√ÉO: {evasion_rate:.1f}% - Classificada como {severity}")
    if evasion_rate > 20:
        print("  ‚ö†Ô∏è  Requer interven√ß√£o urgente da institui√ß√£o")
    
    # Insight 2: Atividade como preditor
    if len(activity_data) > 0 and 'active_activity' in locals() and 'other_activity' in locals():
        if len(active_activity) > 0 and len(other_activity) > 0:
            diff_atividade = active_activity.mean() - other_activity.mean()
            if diff_atividade > 1000:
                print(f"‚Ä¢ TEMPO DE ATIVIDADE: Forte preditor de perman√™ncia")
                print(f"  üìä Diferen√ßa de {diff_atividade:,.0f} horas entre ativos e demais")
            elif diff_atividade > 500:
                print(f"‚Ä¢ TEMPO DE ATIVIDADE: Moderado preditor de perman√™ncia")
                print(f"  üìä Diferen√ßa de {diff_atividade:,.0f} horas entre grupos")
    
    # Insight 3: Padr√µes temporais
    if len(matriculas_mes) > 0:
        mes_pico = matriculas_mes.idxmax()
        if pd.notna(mes_pico):
            print(f"‚Ä¢ SAZONALIDADE: Pico de matr√≠culas em {meses[int(mes_pico)-1]}")
            print("  üìÖ Sugere padr√£o t√≠pico de calend√°rio acad√™mico brasileiro")
    
    # Insight 4: Distribui√ß√£o de atividade
    if 'categoria_counts' in locals():
        baixa_atividade_pct = (categoria_counts.get('Baixa', 0) / total) * 100
        if baixa_atividade_pct > 25:
            print(f"‚Ä¢ ENGAJAMENTO: {baixa_atividade_pct:.0f}% dos estudantes com baixa atividade")
            print("  üí° Oportunidade para estrat√©gias de engajamento precoce")
    
    # 9. RECOMENDA√á√ïES PARA MODELOS PREDITIVOS
    print(f"\nüéØ 9. RECOMENDA√á√ïES PARA MODELOS PREDITIVOS")
    print("-" * 50)
    print("‚Ä¢ Vari√°veis mais promissoras identificadas:")
    print("  1. total_activity_time (tempo de atividade)")
    print("  2. workflow_state (status atual)")
    print("  3. dias_na_plataforma (tempo de perman√™ncia)")
    print("  4. padr√µes sazonais de matr√≠cula")
    
    print(f"\n‚Ä¢ Estrat√©gias de modelagem recomendadas:")
    print("  - Usar t√©cnicas de balanceamento de classes (SMOTE)")
    print("  - Aplicar valida√ß√£o cruzada temporal")
    print("  - Considerar features de engenharia baseadas em tempo")
    print("  - Implementar limiar de decis√£o otimizado para recall")
    
    return df

def main():
    """Executar an√°lise completa"""
    df = analyze_dataset()
    
    if df is not None:
        print(f"\n‚úÖ AN√ÅLISE CONCLU√çDA COM SUCESSO!")
        print(f"üìÑ Use esses insights no seu artigo do TCC")
        print(f"üéì Dados analisados: {len(df):,} registros")
    else:
        print(f"‚ùå Falha na an√°lise dos dados")

if __name__ == "__main__":
    main()